{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with the EB-NeRD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check unique topics for articles (and difference between topics in small and large dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "articles_small = pd.read_parquet(\"data/eb-nerd/ebnerd_small/articles.parquet\")\n",
    "articles_large = pd.read_parquet(\"data/eb-nerd/ebnerd_large/articles.parquet\")\n",
    "\n",
    "\n",
    "exploded_df = articles_small.explode('topics')\n",
    "unique_tags = exploded_df['topics'].unique()\n",
    "unique_tags_list_small = unique_tags.tolist()\n",
    "\n",
    "\n",
    "exploded_df = articles_large.explode('topics')\n",
    "unique_tags = exploded_df['topics'].unique()\n",
    "unique_tags_list_large = unique_tags.tolist()\n",
    "\n",
    "\n",
    "set1 = set(unique_tags_list_small)\n",
    "set2 = set(unique_tags_list_large)\n",
    "diff1 = list(set1 - set2)\n",
    "diff2 = list(set2 - set1)\n",
    "print(diff1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique categories small: ['krimi' 'underholdning' 'sport' 'nyheder' 'sex_og_samliv' 'incoming'\n",
      " 'ferie' 'musik' 'side9' 'nationen' 'forbrug' 'biler' 'haandvaerkeren'\n",
      " 'om_ekstra_bladet' 'plus' 'services' 'horoskoper' 'vin' 'video'\n",
      " 'opinionen' 'bibliotek' 'dagsorden' 'play' 'podcast' 'auto' 'penge']\n",
      "Unique categories large: ['underholdning' 'nyheder' 'sport' 'musik' 'krimi' 'sex_og_samliv' 'ferie'\n",
      " 'biler' 'incoming' 'forbrug' 'webtv' 'bibliotek' 'side9' 'haandvaerkeren'\n",
      " 'plus' 'nationen' 'vin' 'om_ekstra_bladet' 'abonnement' 'services'\n",
      " 'video' 'horoskoper' 'opinionen' 'tilavis' 'eblive' 'dagsorden'\n",
      " 'webmaster-test-sektion' 'migration_catalog' 'podcast' 'play' 'rssfeed'\n",
      " 'auto' 'penge']\n",
      "Categories in small but not in large  []\n",
      "Categories in large but not in small  ['eblive', 'abonnement', 'webmaster-test-sektion', 'webtv', 'tilavis', 'migration_catalog', 'rssfeed']\n"
     ]
    }
   ],
   "source": [
    "unique_categories_small = articles_small['category_str'].unique()\n",
    "print(\"Unique categories small:\", unique_categories_small)\n",
    "\n",
    "unique_categories_large = articles_large['category_str'].unique()\n",
    "print(\"Unique categories large:\", unique_categories_large)\n",
    "\n",
    "set1 = set(unique_categories_small)\n",
    "set2 = set(unique_categories_large)\n",
    "diff1 = list(set1 - set2)\n",
    "diff2 = list(set2 - set1)\n",
    "\n",
    "print('Categories in small but not in large ', diff1)\n",
    "print('Categories in large but not in small ', diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11777\n",
      "11176\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_parquet(\"ebnerd-benchmark\\data\\ebnerd_demo/preprocessed.parquet\")\n",
    "df2 = pd.read_parquet(\"ebnerd-benchmark\\data\\ebnerd_demo/preprocessed_and_title_enhanced.parquet\")\n",
    "\n",
    "print(len(df1))\n",
    "print(len(df2))\n",
    "\n",
    "# # Find IDs in df1 not in df2\n",
    "# unique_in_df1 = df1[~df1['article_id'].isin(df2['article_id'])]\n",
    "\n",
    "# # Find IDs in df2 not in df1\n",
    "# unique_in_df2 = df2[~df2['article_id'].isin(df1['article_id'])]\n",
    "\n",
    "# print(\"Unique in df1:\")\n",
    "# print(len(unique_in_df1))\n",
    "\n",
    "# print(\"Unique in df2:\")\n",
    "# print(len(unique_in_df2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on 'article_id' with a left join\n",
    "merged_df = pd.merge(df1, df2[['article_id', 'title']], on='article_id', how='left', suffixes=('', '_enhanced'))\n",
    "\n",
    "# Replace the title from df1 with the title from df2 if it exists\n",
    "merged_df['title'] = merged_df['title_enhanced'].where(merged_df['title_enhanced'].notna(), merged_df['title'])\n",
    "\n",
    "# Drop the enhanced title column as it's no longer needed\n",
    "merged_df.drop(columns=['title_enhanced'], inplace=True)\n",
    "\n",
    "merged_df.to_parquet(\"ebnerd-benchmark\\data\\ebnerd_demo/preprocessed_and_title_enhanced_fixed.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images/No images statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles with images shown:  2358623\n",
      "Articles without images shown:  227124\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "articles = pd.read_parquet(\"ebnerd-benchmark/data/ebnerd_small/preprocessed_and_images.parquet\")\n",
    "behaviors = pd.read_parquet(\"ebnerd-benchmark/data/ebnerd_small/train/behaviors.parquet\")\n",
    "\n",
    "# Preprocess 'article_id' column in articles for faster access\n",
    "article_id_set = set(articles['article_id'])\n",
    "\n",
    "# Calculate images shown and not shown\n",
    "images_shown = 0\n",
    "no_images_shown = 0\n",
    "\n",
    "# Explode the article_ids_inview to have one per row for easy join\n",
    "behaviors_exploded = behaviors.explode('article_ids_inview')\n",
    "\n",
    "# Join behaviors with articles on article_id\n",
    "merged = behaviors_exploded.join(articles.set_index('article_id'), on='article_ids_inview')\n",
    "\n",
    "# Calculate total\n",
    "total = len(merged)\n",
    "\n",
    "# Vectorized operation to check for image captions\n",
    "merged['has_image'] = merged['image_caption_text'].apply(lambda x: len(str(x)) > 0)\n",
    "\n",
    "# Summarize the results\n",
    "images_shown = merged['has_image'].sum()\n",
    "no_images_shown = total - images_shown\n",
    "\n",
    "print('Articles with images shown: ', images_shown)\n",
    "print('Articles without images shown: ', no_images_shown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Articles with images clicked:  212877\n",
      "Articles without images clicked:  21400\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "articles = pd.read_parquet(\"ebnerd-benchmark/data/ebnerd_small/preprocessed_and_images.parquet\")\n",
    "behaviors = pd.read_parquet(\"ebnerd-benchmark/data/ebnerd_small/train/behaviors.parquet\")\n",
    "\n",
    "# Preprocess 'article_id' column in articles for faster access\n",
    "article_id_set = set(articles['article_id'])\n",
    "\n",
    "# Calculate images shown and not shown\n",
    "images_clicked = 0\n",
    "no_images_clicked = 0\n",
    "\n",
    "# Explode the article_ids_inview to have one per row for easy join\n",
    "behaviors_exploded = behaviors.explode('article_ids_clicked')\n",
    "\n",
    "# Join behaviors with articles on article_id\n",
    "merged = behaviors_exploded.join(articles.set_index('article_id'), on='article_ids_clicked')\n",
    "\n",
    "# Calculate total\n",
    "total = len(merged)\n",
    "\n",
    "# Vectorized operation to check for image captions\n",
    "merged['has_image'] = merged['image_caption_text'].apply(lambda x: len(str(x)) > 0)\n",
    "\n",
    "# Summarize the results\n",
    "images_clicked = merged['has_image'].sum()\n",
    "no_images_clicked = total - images_clicked\n",
    "\n",
    "print('Articles with images clicked: ', images_clicked)\n",
    "print('Articles without images clicked: ', no_images_clicked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability of clicking on an article with an image: 9.03%\n",
      "Probability of clicking on an article without an image: 9.42%\n"
     ]
    }
   ],
   "source": [
    "prob_with_images = images_clicked / images_shown\n",
    "prob_without_images = no_images_clicked / no_images_shown\n",
    "\n",
    "\n",
    "print(f'Probability of clicking on an article with an image: {prob_with_images:.2%}')\n",
    "print(f'Probability of clicking on an article without an image: {prob_without_images:.2%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
